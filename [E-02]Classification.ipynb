{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "spiritual-plain",
   "metadata": {},
   "source": [
    "# [E-02] Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-strand",
   "metadata": {},
   "source": [
    "# 프로젝트 (1) load_digits: 손글씨를 분류해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-facial",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "constitutional-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breeding-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-robinson",
   "metadata": {},
   "source": [
    "* load_digits() 메소드를 이용하여 변수 digits에 데이터를 할당\n",
    "* digits_data에 Feature data 할당\n",
    "* digits_label에 Label data 할당 (target)\n",
    "---\n",
    "* confusion_matrix: 혼동 행렬, 지도 학습으로 훈련된 분류 알고리즘의 성능을 시각화 할 수 있는 표\n",
    "* 각 행은 예측된 클래스의 인스턴스를 나타내며, 각 열은 실제 클래스의 인스턴스를 나타냄 (혹은 반대로 구성)\n",
    "* 이를 이용하여, 각 클래스별 모델의 오답률이 어느 정도인지 확인이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "phantom-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(digits_data.shape)\n",
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-reverse",
   "metadata": {},
   "source": [
    "* digits_data에 저장된 데이터 양과 형식을 확인\n",
    "* 1797개의 digit 데이터가 저장되어 있음을 확인\n",
    "* 각각의 데이터에 64개의 픽셀값이 저장되어 있음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "auburn-athens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits_label.shape)\n",
    "print(digits_label[:20])\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-gregory",
   "metadata": {},
   "source": [
    "* digits_label에 저장된 데이터 양과 형식을 확인\n",
    "* 1797개의 데이터가 저장되어 있음을 확인\n",
    "* digits_label의 처음부터 20개의 데이터를 출력하고, 이를 통해서 0~9까지의 값이 저장되어 있음을 확인\n",
    "* digits 데이터 셋의 Target Name을 출력\n",
    "* Target_Name은 0~9까지의 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arbitrary-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 5620\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-front",
   "metadata": {},
   "source": [
    "* digits 데이터 셋을 Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-eight",
   "metadata": {},
   "source": [
    "## 2. Dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lightweight-crawford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X_train: 1437 number of X_test: 360\n",
      "(1437, 64) (1437,)\n",
      "(360, 64) (360,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                   digits_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print('number of X_train:', len(X_train), 'number of X_test:', len(X_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-workstation",
   "metadata": {},
   "source": [
    "* digits 데이터 셋을 학습용 데이터와 테스트용 데이터로 분리\n",
    "* test 데이터 셋의 크기는 전체 데이터셋의 20%\n",
    "* 즉, 1797개의 데이터 셋 중에서 학습용 데이터는 1437개, 테스트용 데이터는 360개\n",
    "* 기존에 정렬된 데이터를 랜덤으로 섞어서 train set과 test set으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-balance",
   "metadata": {},
   "source": [
    "## 3. Model 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pleasant-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "svm_model = svm.SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "logistic_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-glenn",
   "metadata": {},
   "source": [
    "* 다양한 모델로 학습시키기 위해서, 다음 5개의 모델을 구현\n",
    "    * Decision Tree       (decision_tree)\n",
    "    * Random Forest       (random_forest)\n",
    "    * SVM                 (svm_model)\n",
    "    * SGD Classifier      (sgd_model)\n",
    "    * Logistic Regression (logistic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-modeling",
   "metadata": {},
   "source": [
    "## 3-1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rapid-faculty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "[[42  0  0  1  0  0  0  0  0  0]\n",
      " [ 0 34  3  1  0  1  1  0  0  2]\n",
      " [ 0  0 33  2  0  0  1  1  2  1]\n",
      " [ 0  1  0 31  0  0  0  0  1  1]\n",
      " [ 0  0  1  0 35  0  0  0  1  0]\n",
      " [ 0  1  0  0  0 27  0  0  0  0]\n",
      " [ 0  0  0  0  2  0 26  0  0  0]\n",
      " [ 0  0  0  1  2  1  0 27  0  2]\n",
      " [ 0  5  4  1  1  0  3  0 28  1]\n",
      " [ 0  1  1  2  2  1  0  0  0 25]]\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dicision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dicision_tree))\n",
    "print(confusion_matrix(y_test, y_pred_dicision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-vertical",
   "metadata": {},
   "source": [
    "* Decission Tree를 이용한 결과, accuracy는 86%\n",
    "---\n",
    "* Precision을 확인해보면, 0, 5, 7, 8을 제외한 나머지에서 평균 precision(macro avg)보다 낮은 값을 갖는다.\n",
    "* 0, 5, 7, 8의 경우, 다른 숫자들에 비해서 정밀한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* Recall을 확인해보면, 0, 3, 4, 5, 6을 제외한 나머지에서 평균 recall(macro avg)보다 낮은 값을 갖는다.\n",
    "* 0, 3, 4, 5, 6의 경우, 해당 숫자 내에서 정확한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 5, 6, 7, 8, 9의 오답이 다른 클래스에 비해서 많은 것으로 확인되었다.\n",
    "---\n",
    "* 해당 모델의 정확도는 86%이지만 각각의 label에 따라서 precision과 recall의 편차가 큰 편이기에, 모델의 성능이 좋다고 말할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-bottom",
   "metadata": {},
   "source": [
    "## 3-2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "improving-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "[[42  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 42  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 37  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 27  0  0  0  1]\n",
      " [ 0  0  0  0  1  0 27  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 32  0  1]\n",
      " [ 0  3  0  0  1  1  0  2 36  0]\n",
      " [ 0  0  0  0  0  2  0  0  0 30]]\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-indian",
   "metadata": {},
   "source": [
    "* Random Forest를 이용한 결과, accuracy는 96%\n",
    "---\n",
    "* Precision을 확인해보면, 0, 2, 3, 6, 8을 제외한 나머지에서 평균 precision(macro avg)보다 낮은 값을 갖는다.\n",
    "* 0, 2, 3, 6, 8의 경우, 다른 숫자들에 비해서 정밀한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* Recall을 확인해보면, 1, 2, 3, 4, 5, 6, 7을 제외한 나머지에서 평균 recall(macro avg)보다 낮은 값을 갖는다.\n",
    "* 1, 2, 3, 4, 5, 6, 7의 경우, 해당 숫자 내에서 정확한 예측을 했다고 말할 수 있다.\n",
    "* 특히 8의 경우, 0.84의 recall 값을 갖는 것으로 보아, 실제 8 데이터 중에서 8이라고 예측한 결과가 굉장히 적다고 보여진다.\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 대체적으로 오답이 적지만, 6, 7 클래스의 오답률이 높은 것으로 확인되었다.\n",
    "---\n",
    "* 해당 모델의 정확도는 96%로, 굉장히 높은 정확도를 보여준다. 뿐만 아니라, precision과 recall의 각 label 별 편차가 대체적으로 크지 않고, 전반적으로 0.9 이상의 값을 갖기때문에, 모델의 성능이 좋다고 말할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-estonia",
   "metadata": {},
   "source": [
    "## 3-3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "silent-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 42  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 37  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 28  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  0]\n",
      " [ 0  2  0  0  0  1  0  0 40  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 31]]\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm_model = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm_model))\n",
    "print(confusion_matrix(y_test, y_pred_svm_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-table",
   "metadata": {},
   "source": [
    "* SVM을 이용한 결과, accuracy는 99%\n",
    "* 5개의 모델 중, 가장 높은 accuracy를 보여줌\n",
    "* 그러나, 99%라는 너무 높은 accuracy를 갖기 때문에, 믿을 수 있는 수치인지 의문 \n",
    "---\n",
    "* Precision을 확인해보면, 1, 5에서 평균 precision(macro avg)보다 낮은 값을 갖는다.\n",
    "* 대부분 정밀한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* Recall을 확인해보면, 8, 9에서 평균 recall(macro avg)보다 낮은 값을 갖는다.\n",
    "* 대부분 해당 숫자 내에서 정확한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 전체적인 오답률이 굉장히 낮은 편이다.\n",
    "* 5, 6 클래스에서 오답률이 다른 클래스에 비해서 높은 편임을 확인했다.\n",
    "---\n",
    "* 해당 모델의 정확도는 99%로, 굉장히 높은 정확도를 보여준다. 뿐만 아니라, precision과 recall의 각 label 별 편차가 대체적으로 크지 않고, 전반적으로 0.9 이상의 값을 갖는다.\n",
    "* 그러나 99%의 정확도는 굉장히 높은 수치이며, 해당 모델의 성능에 대한 의심이 생긴다.\n",
    "* 만약 해당 모델의 성능이 사실이라면, 해당 프로젝트에서는 SVM 모델을 사용하는 것이 가장 좋다고 말할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-subject",
   "metadata": {},
   "source": [
    "## 3-4. SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "limiting-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.94      0.71      0.81        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.91      0.91      0.91        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.85      1.00      0.92        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.77      0.93      0.84        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.93       360\n",
      "   macro avg       0.94      0.93      0.93       360\n",
      "weighted avg       0.94      0.93      0.93       360\n",
      "\n",
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 30  0  2  0  1  0  0  8  1]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 31  0  1  0  1  1  0]\n",
      " [ 0  0  0  0 37  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 26  0  2  0]\n",
      " [ 0  0  0  0  1  0  0 32  0  0]\n",
      " [ 0  2  0  0  0  1  0  0 40  0]\n",
      " [ 0  0  0  1  0  2  0  0  1 28]]\n"
     ]
    }
   ],
   "source": [
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sgd_model))\n",
    "print(confusion_matrix(y_test, y_pred_sgd_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-parks",
   "metadata": {},
   "source": [
    "* SGD Claasifier를 이용한 결과, accuracy는 93%\n",
    "---\n",
    "* Precision을 확인해보면, 1, 3, 5를 제외한 나머지에서 평균 precision(macro avg)보다 높은 값을 갖는다.\n",
    "* 1, 3, 5의 경우, 다른 숫자들에 비해서 정밀도가 떨어진다고 말할 수 있다.\n",
    "---\n",
    "* Recall을 확인해보면, 1, 8, 9을 제외한 나머지에서 평균 recall(macro avg)보다 높은 값을 갖는다.\n",
    "* 1, 8, 9의 경우, 해당 숫자 내에서 정확한 예측을 한 비율이 적다고 말할 수 있다.\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 3, 5, 6 클래스의 오답률이 다른 클래스에 비해서 높은 것으로 확인되었다.\n",
    "---\n",
    "* 해당 모델의 정확도는 93%로, 높은 정확도를 보여준다. 그러나, 일부 label에서 precision과 recall 값이 다른 label에 비해서 많이 낮다.\n",
    "* 이러한 이유는, SGD의 특성으로 인한 결과라고 생각된다.\n",
    "    * SGD는 추출된 데이터 한개에 대해서 그래디언트를 계산하고, 경사 하강 알고리즘을 적용하는 방식\n",
    "    * 전체 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터를 사용\n",
    "    * 따라서 속도가 매우 빠르지만, 학습 중간 과정에서 결과의 진폭이 크고 불안정\n",
    "    * 또한, 데이터를 하나씩 처리하기 때문에 오차율이 크고, GPU의 성능을 모두 활용하지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-dictionary",
   "metadata": {},
   "source": [
    "## 3-5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adolescent-somewhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 40  0  0  0  0  0  0  1  1]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  0  0  1  0  0]\n",
      " [ 0  0  0  0 37  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 27  0  0  1  0]\n",
      " [ 0  0  0  0  0  0 27  0  1  0]\n",
      " [ 0  0  0  1  0  0  0 32  0  0]\n",
      " [ 0  2  1  0  1  4  0  0 35  0]\n",
      " [ 0  0  0  1  0  2  0  0  0 29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logistic_model))\n",
    "print(confusion_matrix(y_test, y_pred_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-physiology",
   "metadata": {},
   "source": [
    "* Logistic Regression을 이용한 결과, accuracy는 95%\n",
    "---\n",
    "* Precision을 확인해보면, 5, 8를 제외한 나머지에서 평균 precision(macro avg)보다 높은 값을 갖는다.\n",
    "* 5, 8의 경우, 다른 숫자들에 비해서 정밀도가 떨어진다고 말할 수 있다.\n",
    "---\n",
    "* Recall을 확인해보면, 8, 9을 제외한 나머지에서 평균 recall(macro avg)보다 높은 값을 갖는다.\n",
    "* 8, 9의 경우, 해당 숫자 내에서 정확한 예측을 한 비율이 적다고 말할 수 있다.\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 5, 6, 9 클래스의 오답률이 다른 클래스에 비해서 높은 것으로 확인되었다.\n",
    "---\n",
    "* 해당 모델의 정확도는 95%로, 높은 정확도를 보여준다.\n",
    "* 아래 출력된 오류는 학습에 따른 모델의 convergence가 이루어지지 않았기에 발생된 것으로 확인. 즉, 학습에 대한 모델의 최적화가 이루어지지 않았다.\n",
    "* 아마도, 학습 데이터의 양이 증가하면, 해당 오류를 해결할 수 있지 않을까 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-child",
   "metadata": {},
   "source": [
    "## 4. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-monitor",
   "metadata": {},
   "source": [
    "### accuracy\n",
    "* Decision Tree: 86%\n",
    "* Random Forest: 96%\n",
    "* SVM: 99%\n",
    "* SGD Classifier: 93%\n",
    "* Logistic Regression: 95%\n",
    "---\n",
    "* Decision Tree를 제외한 나머지 4개의 모델은 90% 이상의 정확도를 보여줌\n",
    "* confusion_matrix를 확인해 본 결과, 다른 모델에 비해서 대체적으로 오답률이 높은 것을 확인\n",
    "* Decision Tree를 제외한 나머지 4개의 모델을 이용하는 것이 손글씨 분류에는 적합하다고 판단\n",
    "* 특히, SVM의 경우 99%라는 굉장히 높은 정확도를 보여줌\n",
    "* 따라서 해당 프로젝트에서는 SVM을 사용하는 것이 가장 적합하다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-cambodia",
   "metadata": {},
   "source": [
    "# 프로젝트 (2) load_wine: 와인을 분류해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-budapest",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "olive-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-possibility",
   "metadata": {},
   "source": [
    "* load_wine() 메소드를 이용하여 변수 wine에 데이터를 할당\n",
    "* wine_data에 Feature data 할당\n",
    "* wine_label에 Label data 할당 (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reasonable-feature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "       3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "       1.065e+03])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(wine_data.shape)\n",
    "wine_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "posted-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-magazine",
   "metadata": {},
   "source": [
    "* wine_data에 저장된 데이터 양과 형식을 확인\n",
    "* 178개의 wine 데이터가 저장되어 있음을 확인\n",
    "* feature는 총 13개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "flexible-sitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print(wine_label.shape)\n",
    "print(wine_label[:])\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-coordinate",
   "metadata": {},
   "source": [
    "* wine_label에 저장된 데이터 양과 형식을 확인\n",
    "* 178개의 데이터가 저장되어 있음을 확인\n",
    "* 저장된 label은 class 0, 1, 2의 세 가지 카테고리로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "knowing-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-slovak",
   "metadata": {},
   "source": [
    "* wine 데이터 셋의 Target Name을 출력\n",
    "* Target_Name은 class_0, class_1, class_2\n",
    "* wine 데이터 셋을 Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-ambassador",
   "metadata": {},
   "source": [
    "## 2. Dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "respected-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X_train: 142 number of X_test: 36\n",
      "(142, 13) (142,)\n",
      "(36, 13) (36,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data,\n",
    "                                                   wine_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print('number of X_train:', len(X_train), 'number of X_test:', len(X_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-olympus",
   "metadata": {},
   "source": [
    "* wine 데이터 셋을 학습용 데이터와 테스트용 데이터로 분리\n",
    "* test 데이터 셋의 크기는 전체 데이터셋의 20%\n",
    "* 즉, 178개의 데이터 셋 중에서 학습용 데이터는 142개, 테스트용 데이터는 36개\n",
    "* 기존에 정렬된 데이터를 랜덤으로 섞어서 train set과 test set으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-india",
   "metadata": {},
   "source": [
    "## 3. Model 학습 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-circus",
   "metadata": {},
   "source": [
    "## 3-1. Dicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sunset-beach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2 10]]\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dicision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dicision_tree))\n",
    "print(confusion_matrix(y_test, y_pred_dicision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-ministry",
   "metadata": {},
   "source": [
    "* Decission Tree를 이용한 결과, accuracy는 94%\n",
    "---\n",
    "* Precision을 확인해보면, 'class 1'에서 평균 precision(macro avg)보다 낮은 값을 갖는다.\n",
    "* 'class 0', 'class 2'의 경우, 다른 class에 비해서 정밀한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* Recall을 확인해보면, 'class 2'에서 평균 recall(macro avg)보다 낮은 값을 갖는다.\n",
    "* 'class 0', 'class 1'의 경우, 해당 class 내에서 정확한 예측을 했다고 말할 수 있다.\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, class 2에 대해서만 오답이 발생했다.\n",
    "---\n",
    "* 해당 모델은 94%의 높은 정확도를 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-reason",
   "metadata": {},
   "source": [
    "## 3-2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "partial-monitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-medium",
   "metadata": {},
   "source": [
    "* Random Forest를 이용한 결과, accuracy는 100%\n",
    "---\n",
    "* 해당 모델의 정확도는 100%이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-gnome",
   "metadata": {},
   "source": [
    "## 3-3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bridal-bermuda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n",
      "[[ 6  0  1]\n",
      " [ 1 15  1]\n",
      " [ 0 11  1]]\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm_model = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm_model))\n",
    "print(confusion_matrix(y_test, y_pred_svm_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-collins",
   "metadata": {},
   "source": [
    "* SVM을 이용한 결과, accuracy는 61%\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 전체적으로 오답률이 높았으며, 특히 'class 2'의 경우 대부분이 오답이었다.\n",
    "---\n",
    "* 해당 모델의 정확도는 61%로, 굉장히 낮은 정확도가 측정되었다.\n",
    "* 따라서 해당 Wine 데이터 분류 모델로서는 적합하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-juvenile",
   "metadata": {},
   "source": [
    "## 3-4. SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "satellite-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82         7\n",
      "           1       0.91      0.59      0.71        17\n",
      "           2       0.60      0.75      0.67        12\n",
      "\n",
      "    accuracy                           0.72        36\n",
      "   macro avg       0.74      0.78      0.73        36\n",
      "weighted avg       0.77      0.72      0.72        36\n",
      "\n",
      "[[ 7  0  0]\n",
      " [ 1 10  6]\n",
      " [ 2  1  9]]\n"
     ]
    }
   ],
   "source": [
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sgd_model))\n",
    "print(confusion_matrix(y_test, y_pred_sgd_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-backup",
   "metadata": {},
   "source": [
    "* SGD Classifier를 이용한 결과, accuracy는 71%\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 전체적으로 오답률이 높진 않았지만, 'class 2'의 경우 절반이 오답이었다.\n",
    "---\n",
    "* 해당 모델의 정확도는 71%로, 굉장히 낮은 정확도가 측정되었다.\n",
    "* 따라서 해당 Wine 데이터 분류 모델로서는 적합하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-forth",
   "metadata": {},
   "source": [
    "## 3-5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "configured-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.95      0.96        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n",
      "[[ 6  1  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 12]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logistic_model))\n",
    "print(confusion_matrix(y_test, y_pred_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-firewall",
   "metadata": {},
   "source": [
    "* Logistic Regression을 이용한 결과, accuracy는 97%\n",
    "---\n",
    "* confusion_matrix를 확인해본 결과, 단 하나의 오답만 발생했다.\n",
    "---\n",
    "* 해당 모델의 정확도는 97%로 굉장히 높은 정확도를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-mechanics",
   "metadata": {},
   "source": [
    "## 4. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-aaron",
   "metadata": {},
   "source": [
    "### accuracy\n",
    "* Decision Tree: 94%\n",
    "* Random Forest: 100%\n",
    "* SVM: 61%\n",
    "* SGD Classifier: 71%\n",
    "* Logistic Regression: 97%\n",
    "---\n",
    "* SVM, SGD Classifier를 제외한 나머지 3개의 모델은 90% 이상의 정확도를 보여줌\n",
    "* confusion_matrix를 확인해 본 결과, SVM, SGD Classifier는 오답률이 높았음\n",
    "* 따라서, SVM과 SGD Classifier 모델은 해당 wine 데이터를 분류하기에 적합한 모델이 아니라고 판단\n",
    "---\n",
    "* Random Forest의 경우, 100%라는 굉장히 높은 정확도를 보여줌\n",
    "* 따라서 해당 프로젝트에서는 Random Forest를 사용하는 것이 가장 적합하다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-discrimination",
   "metadata": {},
   "source": [
    "# 프로젝트 (3) load_breast_cancer: 유방암 여부를 진단해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-press",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "leading-reply",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "cancer_data = cancer.data\n",
    "cancer_label = cancer.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-flower",
   "metadata": {},
   "source": [
    "* load_breast_cancer() 메소드를 이용하여 변수 cancer에 데이터를 할당\n",
    "* cancer_data에 Feature data 할당\n",
    "* cancer_label에 Label data 할당 (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "precious-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "       3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "       8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "       3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "       1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cancer_data.shape)\n",
    "cancer_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "falling-registrar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-placement",
   "metadata": {},
   "source": [
    "* cancer_data에 저장된 데이터 양과 형식을 확인\n",
    "* 569개의 wine 데이터가 저장되어 있음을 확인\n",
    "* feature는 총 30개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "palestinian-phase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(cancer_label.shape)\n",
    "print(cancer_label[:])\n",
    "print(cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-offense",
   "metadata": {},
   "source": [
    "* cancer_label에 저장된 데이터 양과 형식을 확인\n",
    "* 569개의 데이터가 저장되어 있음을 확인\n",
    "* cancer_label의 0, 1의 값이 저장되어 있음을 확인\n",
    "* cancer 데이터 셋의 Target Name을 출력\n",
    "* Target_Name은 'malignant', 'benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "amazing-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-verse",
   "metadata": {},
   "source": [
    "* cancer 데이터 셋을 Describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-generation",
   "metadata": {},
   "source": [
    "## 2. Dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "drawn-wrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X_train: 455 number of X_test: 114\n",
      "(455, 30) (455,)\n",
      "(114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data,\n",
    "                                                   cancer_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print('number of X_train:', len(X_train), 'number of X_test:', len(X_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-arkansas",
   "metadata": {},
   "source": [
    "* cancer 데이터 셋을 학습용 데이터와 테스트용 데이터로 분리\n",
    "* test 데이터 셋의 크기는 전체 데이터셋의 20%\n",
    "* 즉, 569의 데이터 셋 중에서 학습용 데이터는 455개, 테스트용 데이터는 114개\n",
    "* 기존에 정렬된 데이터를 랜덤으로 섞어서 train set과 test set으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-democracy",
   "metadata": {},
   "source": [
    "## 3. Model 학습 및 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-design",
   "metadata": {},
   "source": [
    "## 3-1. Dicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "similar-coral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "[[33  7]\n",
      " [ 3 71]]\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dicision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dicision_tree))\n",
    "print(confusion_matrix(y_test, y_pred_dicision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-skating",
   "metadata": {},
   "source": [
    "* Decission Tree를 이용한 결과, accuracy는 91%\n",
    "---\n",
    "* 해당 데이터는 악성/양성 종양에 대한 데이터이므로, accuracy 자체보다는, Recall의 값이 중요\n",
    "* Recall은 0.82의 값으로 측정되었으며, test set 중, 7명의 악성 종양 환자에게 양성 종양이라는 잘못된 판단을 함\n",
    "---\n",
    "* 해당 모델은 91%의 높은 정확도를 보인다.\n",
    "* 하지만, Recall이 0.82로, 7명의 악성 종양 환자에게 양성 종양이라는 잘못된 판단을 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-overall",
   "metadata": {},
   "source": [
    "## 3-2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "contrary-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "[[40  0]\n",
      " [ 0 74]]\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-qatar",
   "metadata": {},
   "source": [
    "* Random Forest를 이용한 결과, accuracy는 100%\n",
    "---\n",
    "* 해당 모델의 정확도는 100%이다.\n",
    "* 해당 모델은 모든 악성 종양 환자에게 정확한 진단을 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-india",
   "metadata": {},
   "source": [
    "## 3-3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "wireless-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "[[29 11]\n",
      " [ 0 74]]\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm_model = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm_model))\n",
    "print(confusion_matrix(y_test, y_pred_svm_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-heath",
   "metadata": {},
   "source": [
    "* SVM를 이용한 결과, accuracy는 90%\n",
    "---\n",
    "* 해당 데이터는 악성/양성 종양에 대한 데이터이므로, accuracy 자체보다는, Recall의 값이 중요\n",
    "* Recall은 0.72의 값으로 측정되었으며, test set 중, 11명의 악성 종양 환자에게 양성 종양이라는 잘못된 판단을 함\n",
    "---\n",
    "* 해당 모델은 90%의 높은 정확도를 보인다.\n",
    "* 하지만, Recall이 0.72로, 11명의 환자에게 양성 종양이라는 잘못된 판단을 했다.\n",
    "* 따라서 해당 데이터에 적합한 모델이 아니라고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-working",
   "metadata": {},
   "source": [
    "## 3-4. SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ultimate-amber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84        40\n",
      "           1       0.91      0.92      0.91        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.87      0.87       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "[[33  7]\n",
      " [ 6 68]]\n"
     ]
    }
   ],
   "source": [
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sgd_model))\n",
    "print(confusion_matrix(y_test, y_pred_sgd_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-treasury",
   "metadata": {},
   "source": [
    "* SGD Classifier를 이용한 결과, accuracy는 89%\n",
    "---\n",
    "* 해당 데이터는 악성/양성 종양에 대한 데이터이므로, accuracy 자체보다는, Recall의 값이 중요\n",
    "* Recall은 0.75의 값으로 측정되었으며, test set 중, 10명의 악성 종양 환자에게 양성 종양이라는 잘못된 판단을 함\n",
    "---\n",
    "* 해당 모델은 89%의 높은 정확도를 보인다.\n",
    "* 하지만, Recall이 0.75로, 10명의 환자에게 양성 종양이라는 잘못된 판단을 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-boutique",
   "metadata": {},
   "source": [
    "## 3-5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "chief-kingston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        40\n",
      "           1       0.91      1.00      0.95        74\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.96      0.91      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "[[33  7]\n",
      " [ 0 74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logistic_model))\n",
    "print(confusion_matrix(y_test, y_pred_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-wireless",
   "metadata": {},
   "source": [
    "* Logistic Regression를 이용한 결과, accuracy는 94%\n",
    "---\n",
    "* 해당 데이터는 악성/양성 종양에 대한 데이터이므로, accuracy 자체보다는, Recall의 값이 중요\n",
    "* Recall은 0.82의 값으로 측정되었으며, test set 중, 7명의 악성 종양 환자에게 양성 종양이라는 잘못된 판단을 함\n",
    "---\n",
    "* 해당 모델은 94%의 높은 정확도를 보인다.\n",
    "* 하지만, Recall이 0.82로, 7명의 환자에게 양성 종양이라는 잘못된 판단을 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-technology",
   "metadata": {},
   "source": [
    "## 4. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-correspondence",
   "metadata": {},
   "source": [
    "### accuracy\n",
    "* Decision Tree: 91% (Recall = 0.82)\n",
    "* Random Forest: 100% (Recall = 1.00)\n",
    "* SVM: 90% (Recall = 0.72)\n",
    "* SGD Classifier: 89% (Recall = 0.75)\n",
    "* Logistic Regression: 94% (Recall = 0.82)\n",
    "---\n",
    "* 모든 모델이 89% 이상의 정확도를 보여줌\n",
    "---\n",
    "* 해당 데이터는 정확도보다, Recall 값이 중요한 예제\n",
    "* 따라서 모든 모델들의 Recall 값을 확인하는 것이 중요\n",
    "* Random Forest를 제외한 나머지 모델에서는 Recall 값이 0.72~0.82 사이의 값을 갖는 것으로 확인\n",
    "* 즉, 악성 종양 환자를 양성 종양 환자로 판단한 케이스가 7~10명\n",
    "* 따라서 Random Forest를 제외한 나머지 4개의 모델은 해당 데이터에 적합한 모델이 아니라고 판단\n",
    "---\n",
    "* Random Forest의 경우, 100%라는 굉장히 높은 정확도를 보여줌\n",
    "* 또한, Recall값이 1.00으로, 잘못된 분류를 한 케이스가 하나도 없음\n",
    "* 따라서 해당 프로젝트에서는 Random Forest를 사용하는 것이 가장 적합하다고 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-platinum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
